{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import func, inspect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an engine for the  FemaData.db database\n",
    "engine = create_engine(\"sqlite:///../data/femadata.sqlite\", echo=False)\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reflect Database into ORM classes\n",
    "Base = automap_base()\n",
    "Base.prepare(engine, reflect=True)\n",
    "#Base.classes.keys()  #- if no primary key the table isn't picked up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "############  RIGHT HERE I CAN DROP SOME COLUMNS\n",
    "\n",
    "abbr_state = pd.read_csv(\"../rawDAta/50_us_states_all_dataAbbrv.csv\")\n",
    "# abbr_state.drop(columns=['state_apStyle'], inplace=True)\n",
    "abbr_state.rename(columns={\"state_caps\": \"STATE_CAPS\",\"state_abbrv\": \"STATE_ABBRV\", \\\n",
    "                           \"state_title\": \"STATE_TITLE\", \"state_apStyle\": \"STATE_APSTYLE\"}, inplace=True)\n",
    "\n",
    "abbr_state.to_sql('state_abbrv', conn, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tmher\\Anaconda3\\envs\\pandas\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (29,34,35,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# noaa_1995_df = pd.read_csv(\"../rawDAta/StormEvents_details-ftp_v1.0_d1995.csv\")\n",
    "# noaa_1996_df = pd.read_csv(\"../rawDAta/StormEvents_details-ftp_v1.0_d1996.csv\")\n",
    "# noaa_1997_df = pd.read_csv(\"../rawDAta/StormEvents_details-ftp_v1.0_d1997.csv\")\n",
    "# noaa_1998_df = pd.read_csv(\"../rawDAta/StormEvents_details-ftp_v1.0_d1998.csv\")\n",
    "# noaa_1999_df = pd.read_csv(\"../rawDAta/StormEvents_details-ftp_v1.0_d1999.csv\")\n",
    "noaa_2000_df = pd.read_csv(\"../rawDAta/StormEvents_details-ftp_v1.0_d2000.csv\")\n",
    "noaa_2001_df = pd.read_csv(\"../rawDAta/StormEvents_details-ftp_v1.0_d2001.csv\")\n",
    "noaa_2002_df = pd.read_csv(\"../rawDAta/StormEvents_details-ftp_v1.0_d2002.csv\")\n",
    "noaa_2003_df = pd.read_csv(\"../rawDAta/StormEvents_details-ftp_v1.0_d2003.csv\")\n",
    "noaa_2004_df = pd.read_csv(\"../rawDAta/StormEvents_details-ftp_v1.0_d2004.csv\")\n",
    "noaa_2005_df = pd.read_csv(\"../rawDAta/StormEvents_details-ftp_v1.0_d2005.csv\")\n",
    "noaa_2006_df = pd.read_csv(\"../rawDAta/StormEvents_details-ftp_v1.0_d2006.csv\")\n",
    "noaa_2007_df = pd.read_csv(\"../rawDAta/StormEvents_details-ftp_v1.0_d2007.csv\")\n",
    "noaa_2008_df = pd.read_csv(\"../rawDAta/StormEvents_details-ftp_v1.0_d2008.csv\")\n",
    "noaa_2009_df = pd.read_csv(\"../rawDAta/StormEvents_details-ftp_v1.0_d2009.csv\")\n",
    "noaa_2010_df = pd.read_csv(\"../rawDAta/StormEvents_details-ftp_v1.0_d2010.csv\")\n",
    "noaa_2011_df = pd.read_csv(\"../rawDAta/StormEvents_details-ftp_v1.0_d2011.csv\")\n",
    "noaa_2012_df = pd.read_csv(\"../rawDAta/StormEvents_details-ftp_v1.0_d2012.csv\")\n",
    "noaa_2013_df = pd.read_csv(\"../rawDAta/StormEvents_details-ftp_v1.0_d2013.csv\")\n",
    "noaa_2014_df = pd.read_csv(\"../rawDAta/StormEvents_details-ftp_v1.0_d2014.csv\")\n",
    "noaa_2015_df = pd.read_csv(\"../rawDAta/StormEvents_details-ftp_v1.0_d2015.csv\")\n",
    "noaa_2016_df = pd.read_csv(\"../rawDAta/StormEvents_details-ftp_v1.0_d2016.csv\")\n",
    "noaa_2017_df = pd.read_csv(\"../rawDAta/StormEvents_details-ftp_v1.0_d2017.csv\")\n",
    "noaa_2018_df = pd.read_csv(\"../rawDAta/StormEvents_details-ftp_v1.0_d2018.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merge all the dataframes into one\n",
    "\n",
    "noaa_all = pd.DataFrame()\n",
    "\n",
    "# for i in range(1995,1997):\n",
    "#     dfName = 'noaa_' + str(i) + '_df'\n",
    "#     noaa_all = noaa_all.append(dfName, ignore_index = True)\n",
    "    \n",
    "# noaa_all  \n",
    "\n",
    "# noaa_all = noaa_all.append(noaa_1995_df, ignore_index = True)\n",
    "# noaa_all = noaa_all.append(noaa_1996_df, ignore_index = True)\n",
    "# noaa_all = noaa_all.append(noaa_1997_df, ignore_index = True)\n",
    "# noaa_all = noaa_all.append(noaa_1998_df, ignore_index = True)\n",
    "# noaa_all = noaa_all.append(noaa_1999_df, ignore_index = True)\n",
    "noaa_all = noaa_all.append(noaa_2000_df, ignore_index = True)\n",
    "noaa_all = noaa_all.append(noaa_2001_df, ignore_index = True)\n",
    "noaa_all = noaa_all.append(noaa_2002_df, ignore_index = True)\n",
    "noaa_all = noaa_all.append(noaa_2003_df, ignore_index = True)\n",
    "noaa_all = noaa_all.append(noaa_2004_df, ignore_index = True)\n",
    "noaa_all = noaa_all.append(noaa_2005_df, ignore_index = True)\n",
    "noaa_all = noaa_all.append(noaa_2006_df, ignore_index = True)\n",
    "noaa_all = noaa_all.append(noaa_2007_df, ignore_index = True)\n",
    "noaa_all = noaa_all.append(noaa_2008_df, ignore_index = True)\n",
    "noaa_all = noaa_all.append(noaa_2009_df, ignore_index = True)\n",
    "noaa_all = noaa_all.append(noaa_2010_df, ignore_index = True)\n",
    "noaa_all = noaa_all.append(noaa_2011_df, ignore_index = True)\n",
    "noaa_all = noaa_all.append(noaa_2012_df, ignore_index = True)\n",
    "noaa_all = noaa_all.append(noaa_2013_df, ignore_index = True)\n",
    "noaa_all = noaa_all.append(noaa_2014_df, ignore_index = True)\n",
    "noaa_all = noaa_all.append(noaa_2015_df, ignore_index = True)\n",
    "noaa_all = noaa_all.append(noaa_2016_df, ignore_index = True)\n",
    "noaa_all = noaa_all.append(noaa_2017_df, ignore_index = True)\n",
    "noaa_all = noaa_all.append(noaa_2018_df, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BEGIN_YEARMONTH', 'BEGIN_DAY', 'BEGIN_TIME', 'END_YEARMONTH',\n",
       "       'END_DAY', 'END_TIME', 'EPISODE_ID', 'EVENT_ID', 'STATE', 'STATE_FIPS',\n",
       "       'YEAR', 'MONTH_NAME', 'EVENT_TYPE', 'CZ_TYPE', 'CZ_FIPS', 'CZ_NAME',\n",
       "       'WFO', 'BEGIN_DATE_TIME', 'CZ_TIMEZONE', 'END_DATE_TIME',\n",
       "       'INJURIES_DIRECT', 'INJURIES_INDIRECT', 'DEATHS_DIRECT',\n",
       "       'DEATHS_INDIRECT', 'DAMAGE_PROPERTY', 'DAMAGE_CROPS', 'SOURCE',\n",
       "       'MAGNITUDE', 'MAGNITUDE_TYPE', 'FLOOD_CAUSE', 'CATEGORY', 'TOR_F_SCALE',\n",
       "       'TOR_LENGTH', 'TOR_WIDTH', 'TOR_OTHER_WFO', 'TOR_OTHER_CZ_STATE',\n",
       "       'TOR_OTHER_CZ_FIPS', 'TOR_OTHER_CZ_NAME', 'BEGIN_RANGE',\n",
       "       'BEGIN_AZIMUTH', 'BEGIN_LOCATION', 'END_RANGE', 'END_AZIMUTH',\n",
       "       'END_LOCATION', 'BEGIN_LAT', 'BEGIN_LON', 'END_LAT', 'END_LON',\n",
       "       'EPISODE_NARRATIVE', 'EVENT_NARRATIVE', 'DATA_SOURCE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noaa_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to drop   df.drop(columns=['B', 'C'])\n",
    "# 'last_date_modified',\n",
    "noaa_all.drop(columns=['WFO', 'BEGIN_DATE_TIME', 'BEGIN_DAY', \\\n",
    "                       'BEGIN_TIME', 'CZ_TIMEZONE', 'END_YEARMONTH', \\\n",
    "                       'END_DAY', 'END_TIME', 'END_DATE_TIME', 'CATEGORY', \\\n",
    "                       'SOURCE', 'FLOOD_CAUSE', 'TOR_LENGTH', 'TOR_WIDTH', \\\n",
    "                       'TOR_OTHER_WFO', 'TOR_OTHER_CZ_STATE', \\\n",
    "                       'TOR_OTHER_CZ_FIPS', 'TOR_OTHER_CZ_NAME', \\\n",
    "                       'BEGIN_RANGE', 'BEGIN_AZIMUTH', 'BEGIN_LOCATION', \\\n",
    "                       'END_RANGE', 'END_AZIMUTH', 'END_LOCATION', \\\n",
    "                       'DATA_SOURCE',   \\\n",
    "                       'BEGIN_YEARMONTH', 'MONTH_NAME', 'CZ_TYPE', \\\n",
    "                       'CZ_FIPS', 'CZ_NAME', 'MAGNITUDE', 'MAGNITUDE_TYPE', \\\n",
    "                       'BEGIN_LAT', 'BEGIN_LON', 'END_LAT', 'END_LON', \\\n",
    "                       'EPISODE_NARRATIVE', 'EVENT_NARRATIVE' \\\n",
    "                       ], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EPISODE_ID</th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>STATE</th>\n",
       "      <th>STATE_FIPS</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>EVENT_TYPE</th>\n",
       "      <th>INJURIES_DIRECT</th>\n",
       "      <th>INJURIES_INDIRECT</th>\n",
       "      <th>DEATHS_DIRECT</th>\n",
       "      <th>DEATHS_INDIRECT</th>\n",
       "      <th>DAMAGE_PROPERTY</th>\n",
       "      <th>DAMAGE_CROPS</th>\n",
       "      <th>TOR_F_SCALE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1104812</td>\n",
       "      <td>5165377</td>\n",
       "      <td>FLORIDA</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>Extreme Cold/Wind Chill</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1104812</td>\n",
       "      <td>5165378</td>\n",
       "      <td>FLORIDA</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>Extreme Cold/Wind Chill</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1104812</td>\n",
       "      <td>5165379</td>\n",
       "      <td>FLORIDA</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>Extreme Cold/Wind Chill</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1105342</td>\n",
       "      <td>5165449</td>\n",
       "      <td>WEST VIRGINIA</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>Winter Storm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1101140</td>\n",
       "      <td>5172568</td>\n",
       "      <td>MISSISSIPPI</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>Thunderstorm Wind</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EPISODE_ID  EVENT_ID          STATE  STATE_FIPS  YEAR  \\\n",
       "0     1104812   5165377        FLORIDA        12.0  2000   \n",
       "1     1104812   5165378        FLORIDA        12.0  2000   \n",
       "2     1104812   5165379        FLORIDA        12.0  2000   \n",
       "3     1105342   5165449  WEST VIRGINIA        54.0  2000   \n",
       "4     1101140   5172568    MISSISSIPPI        28.0  2000   \n",
       "\n",
       "                EVENT_TYPE  INJURIES_DIRECT  INJURIES_INDIRECT  DEATHS_DIRECT  \\\n",
       "0  Extreme Cold/Wind Chill                0                  0              0   \n",
       "1  Extreme Cold/Wind Chill                0                  0              0   \n",
       "2  Extreme Cold/Wind Chill                0                  0              0   \n",
       "3             Winter Storm                0                  0              0   \n",
       "4        Thunderstorm Wind                0                  0              0   \n",
       "\n",
       "   DEATHS_INDIRECT DAMAGE_PROPERTY DAMAGE_CROPS TOR_F_SCALE  \n",
       "0                0             NaN          NaN         NaN  \n",
       "1                0             NaN          NaN         NaN  \n",
       "2                0             NaN          NaN         NaN  \n",
       "3                0             NaN          NaN         NaN  \n",
       "4                0              2K          NaN         NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noaa_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title case the State field\n",
    "noaa_all['STATE'] = noaa_all[\"STATE\"].str.title() \n",
    "# noaa_all[\"STATE\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reference, save csv with count of all types\n",
    "\n",
    "countOfTYpes = noaa_all.EVENT_TYPE.value_counts()\n",
    "countOfTYpes.to_csv(\"../data/countOfTypes.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter dataset to events we are interested in.\n",
    "\n",
    "noaa_cats = noaa_all.loc[(noaa_all['EVENT_TYPE'] == 'Flood') | (noaa_all['EVENT_TYPE'] == 'Tornado') | (noaa_all['EVENT_TYPE'] == 'Hurrincane') | (noaa_all['EVENT_TYPE'] == 'Wildfire')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- store the noaa_cats all in db as all_events\n",
    "noaa_cats.to_sql('all_events', conn, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create table nmbr_events.  State, total number of events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qry = 'SELECT STATE, count(STATE) as NMBR_EVENTS \\\n",
    "FROM all_events \\\n",
    "GROUP BY STATE;'\n",
    "\n",
    "nmbr_events = pd.read_sql(qry, conn)\n",
    "\n",
    "# nmbr_events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create/load to db\n",
    "nmbr_events.to_sql('nmbr_events', conn, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create table events_deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEATHS_DIRECT DEATHS_INDIRECT not equal to zero.\n",
    "noaa_cats_noZero =noaa_cats.loc[(noaa_cats[\"DEATHS_DIRECT\"]  != 0 ) | (noaa_cats[\"DEATHS_INDIRECT\"]  != 0 )]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "noaa_cats_noZero.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noaa_cats_noZero.to_csv('../data/noaa_cats_nonZero.csv',  header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load table events with all non zero data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data of events with deaths to table events_deaths\n",
    "noaa_cats_noZero.to_sql('events_deaths', conn, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sum_state_death table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sum_state_event table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sum_state_event_year table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add state abbr to tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_events\n",
    "qry = 'SELECT * FROM all_events as s \\\n",
    "JOIN state_abbrv as a \\\n",
    "ON s.STATE = a.STATE_TITLE;'\n",
    "all_event_df = pd.read_sql(qry, conn)\n",
    "# index STATE_CAPS\n",
    "all_event_df.drop(columns=['index', 'STATE_CAPS', 'STATE_TITLE', 'STATE_APSTYLE'], inplace=True)\n",
    "\n",
    "# all_event_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_event_df.to_sql('all_events', conn, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# events table\n",
    "qry = 'SELECT * FROM events_deaths as s \\\n",
    "JOIN state_abbrv as a \\\n",
    "ON s.STATE = a.STATE_TITLE;'\n",
    "event_df = pd.read_sql(qry, conn)\n",
    "\n",
    "# event_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index STATE_CAPS\n",
    "event_df.drop(columns=['index', 'STATE_CAPS', 'STATE_TITLE', 'STATE_APSTYLE'], inplace=True)\n",
    "event_df.to_sql('events_deaths', conn, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nmbr_events table\n",
    "qry = 'SELECT * FROM nmbr_events as s \\\n",
    "JOIN state_abbrv as a \\\n",
    "ON s.STATE = a.STATE_TITLE;'\n",
    "nmbr_events_df = pd.read_sql(qry, conn)\n",
    "\n",
    "# index STATE_CAPS\n",
    "nmbr_events_df.drop(columns= ['index', 'STATE_CAPS', 'STATE_TITLE', 'STATE_APSTYLE'], inplace=True)\n",
    "nmbr_events_df.to_sql('nmbr_events', conn, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create some json for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put out nmbr_events json for testing\n",
    "qry = \"select * from nmbr_events\"\n",
    "nmbr_events = pd.read_sql(qry, conn)\n",
    "nmbr_events.to_json('../data/nmbr_events.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pandas]",
   "language": "python",
   "name": "conda-env-pandas-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
